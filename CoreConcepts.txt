System Design Core Concepts


- Scaling
    > Horizontal Scaling
        * Add MORE machines (servers, databases, etc.) to a system
        * Often more costly
        * Most modern systems use "Consistent Hashing" to distribute work across a set of machines
    > Vertical Scaling
        * Add BIGGER machines
        * Add more resources (compute power) to a single machine to increase its capacity
    > Note
        * One of the most important considerations in system design
        * When encountering a scaling bottlenock, make sure to not throw more machines to a bad design


- Work Distribution
    > First challenge of horizontal scaling is getting the work to the right machine
    > Often via a load balancer, which chooses the worker node from a group to use for an incoming request
        * There are many difference strategies, however simple round robin allocation is often sufficient
    > For asynchronous jobs, it's often a queueing system
    > Work distribution needs to try to keep load on the system AS EVEN AS POSSIBLE
        * If using a hash map to distribute work across a set of nodes,  then it's possible that one mode
          is receiving a disproportionate amount of work because of the distribution of incoming requests.


- Data Distribution
    > In some systems data distribution implies keeping data in-mempory on the node that's processing the request
    > More frequently, data distribution implies keeping data in a database that's shared across all nodes
        * Partition data such that a single node can access the data without needing to communicate to another node
        * If communicattion IS needed, then ensure the number of receiver nodes is as small as possible
            + Fan-out method
    > Inherently, horizontal scaling on data introduces synchronization challenges
        * System is either
            1. Reading or writing data to a shared database which is a network hop away (~ 1-10 ms, ideally)
            2. Keeping multiple copies across each server
        * This means race conditions and consistentency challenges, so a "Distributed Lock" maybe needed
    > Note
        * If system involves geography, there's a good chance you have the option to partion by 'REGION_ID'.
          For many systems that involve physical location, this a great way to scale because for many problems
          a given user will only be concerned with data or around a particular location.
          Example, a user in the user US doesn't need to know about data in Europe.
        * Data distribution helps keep data consistent


- CAP Theorem
    > Fundamental concept in distributed systems that states a system can only have TWO of THREE properties
        1. Consistency
            * All nodes in the system will see the data at the same time
            * When a write occurs, all subsequent reads will return that value, regardless of the worker node
            * However, during a network partition, some nodes may become unavailable
        2. Availability
            * Every request will receive a response, even during network partitions
            * Tradeoff is that different nodes may temporarily have different versions of the data
            * System will eventually reconcile these differences, but there's no guarantee about when it happens
        3. Partition Tolerance
            * Network partitions are unavoidable, this means choosing between CONSISTENCY and AVAILABILITY
    > Note
        * In a system design interview, availability should be the default choice
        * Only need strong consistency in systems where reading stale data is unacceptable
            + Inventory management systems, where stock levels need to be precisely tracked to avoid overselling
            + Booking systems for limited resources (airline seats, hotel rooms) to prevent double booking
            + Banking systems where the balance of an account must be consistent across all nodes to prevent fraud


- Locking
    > Systems may have shared resources which can only be accessed by one applicaiton/client at a time
        * Example might be a shared counter (like inventory units) or an interface to a physical device
    > Locks happens at every scale of computer systems
        * Operation system kernel
        * User applications
        * Databases
        * Distributed locked
    > Three main considerations when employing locks
        1. Granularity of the Lock
            * Locks should be as fine-grained as possible
            * Want to lock as little as possible so nothing is blocking other clients from accessing the system
        2. Duration of the Lock
            * Locks should be held for a SHORT as possible
            * Want to lock only for the duration of the critical section
            * For example, when updateing a user's profile, system should only lock for the duration of the update
              and not for the entire request
        3. Whether System can Bypass the Lock
            * In many cases, a lock can be avoid by employing an "optimistic" concurrency control strategy,
              especially if the work to be done is either read-only or can be retired.
            * Optimistic concurrency control makes the assumption that most of the time the application will
              not have contention (or multiple people trying to lock at the same time) in a system
            * However this will not work for applications that need to apply critical logic such as
              updating a user's bak account balance
    > Note
        * Race condition - Situation where multiple clients try to access the same resource at the same time.
                         - Can lead to data corruption, lost updates, and more.


- Indexing
    > Indexing is about making data faster to query
        * Many systems can tolerate slow writes but can't tolerate slow reads
        * Indexing is the process of creating a data structure that makes reads faster
        * Prevents from having to scan every row in the database
        * Designed to make common queries more efficient
            ^ If want to query all post by a given use,
              then in the Posts table create an index for the column `userId`
    > Most basic method of indexing is simply keeping data in a hash map by a specific key
        * When need to grab data by that key, can do it in O(1) time
        * No need to scan entire database
    > Another way is to keep data in a sorted list
        * Allows binary search to find the data in O(log(n))
        * Common way of indexing data in databases
    > Specialized Indexes
        * In addition to basic indexing strategies above, there are specialized indexes for specific problems
        * For example, geospatial indexes are used to index location location
            ^ This is useful for systems that need to do things like find the nearest resturant or store
        * Vector databases are used to index high-dimensional data
            ^ This is useful for systems that need to do things like find similar images or similar documents
        * Full-text indexes are used to index text data
            ^ This is useful for systems that need to do things like search for documents or tweets
        * Many mature databases like Postgres support extensions that allows creation of specialized indexes
        * Elastic Search is the recommended specialized index
            ^ Supoorts full-text indexes, geospatial indexes, and vector indexes
            ^ Can set up ElasticSearch to index most databases via Change Data Capture (CDC) where the cluster
              is listening to changes coming from the database and updating its indexes accordingly
            ^ NOTE: By using CDC, a new point of failure and source of latency will be introduced
            ^ Primary Database --> Change Data Capture (CDC) --> Elastic Search


- Communication Protocols
    > Protocols are the most important part of software engineering
    > Most system can be built with a combination of HTTP(S), SSE or long polling, and Websockets
        * Browsers and apps are built to handle these protocols and easy to implement
    > Two different categories
        1. Internal
            * HTTP(S)
                ^ Use for APIs with simple request and responses
                ^ Since each request is stateless, the API can be scaled horizontally
                  by placing it behind a loead balancer
            * gRPC
                ^ Built on HTTP/2 for high-performance communication
                ^ Uses Protocol Buffers (protobuf) instead of JSON
                ^ Supports streaming (client, server, or both)
                ^ Best for INTERNAL microservice communication
        2. External
            * REST (Request -> Response)
                ^ Can expose an REST API to the application 
                ^ Long polling with the scalability of HTTP(S) are great for realtime updates of Websockets
                ^ With long polling, clients make a request to the server and server
                  holds the request until it has new data to send to the client.
                ^ Once data is sent, client makes another request and the process repeats
            * SSE (Server-Sent Events)
                ^ Great way to send updates from the server to the client
                ^ Similar to long polling, but more efficient for unidirectional communication
                ^ Allows the server to push updates to the client whenever new data is available,
                  without the client having to make repeated requests as in long polling
                ^ Achieved through a single, long-lived HTTP connection, making it more suitable for 
                  scenarios where the server frequently updates data that needs to be sent to the client
                ^ Unlike Websockets, SSE is designed specifically for server-to-client communication and
                  does not support client-to-server messaging
            * Websockets (Bi-directional Channel)
                ^ Necessary for realtime, bidirectional communication between client and server
                ^ Common pattern is to use a message broker to handle the communication between the 
                  client and server and for the backend services to communicate with the message brokers
                ^ This ensures the system doesn't need to maintain long connections to every backend service 
    > Note
        * Statefulness is a major source of complexity for systems
        * Relegating the state to a message broker or database is a great way to simplify a system
        * Enables services to be stateless and horizontally scalable while still maintaining stateful
          connunication with the clients


- Security
    > Authentication/Authorization
        * In many systems an API will be exposed to users which needs to be locked down to only specific users
        * Delegating this work to either an API Gateway or a dedicated serice like Auth0 is sufficient
    > Encryption
        * When handling sensitive data, it's important to make sure to keep it from being exposed
        * Sensitive data can be often be useful for the end-user to control the keys
        * For data at rest, its best to use a database that supports encryption or encrypt data before storing
    > Data Proection
        * Process of ensuring that data is protected from unauthorized access, use, or disclosure
        * Frequently, production system are concerned with data that's sensitive when exposed but might not
          be within an authorization path
            ^ i.e. user's data might be exposed via a createFriendRequest endpoint


- Monitoring
    > Infrastructure Monitoring
        * Process of monitoring the health and performance of system's infrastructure
        * Incluces things like CPU usage, memory usage, disk usage, and network usage
        * Often done with a tool like Datadog or New Relic
    > Service-Level Monitoring
        * Process of monitoring the health and performance of the services
        * Includes things like request latency, error rates, and throughput
    > Application-Level Monitoring
        * Process of monitoring the health and performance of the application
        * Includes things like the number of active users, sessions, and devices
        * Could also include key business metrics for the business
        * Often done with a tool like Google Analytics
        * Most important leve lof monitoring for product designs
